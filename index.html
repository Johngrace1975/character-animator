<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Talking Character</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <style>
    body {
      margin: 0;
      background: #0f172a;
      color: white;
      font-family: Arial, sans-serif;
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100vh;
    }

    .app {
      text-align: center;
    }

    .character {
      position: relative;
      display: inline-block;
      width: 220px;
      height: 220px;
    }

    .character img {
      width: 100%;
      height: 100%;
      display: block;
    }

    .mouth {
      position: absolute;
      bottom: 40px; /* adjust this to match your character‚Äôs mouth */
      left: 50%;
      transform: translateX(-50%);
      width: 60px;
      height: 10px;
      background: white;
      border-radius: 10px;
      transition: height 0.1s;
    }

    button {
      padding: 10px 20px;
      margin: 5px;
      font-size: 16px;
      border: none;
      border-radius: 8px;
      cursor: pointer;
    }

    .record {
      background: #22c55e;
    }

    .stop {
      background: #ef4444;
      color: white;
    }
  </style>
</head>
<body>

  <div class="app">
    <div class="character">
      <img id="charImage" src="character.png" alt="Character" />
      <div id="mouth" class="mouth"></div>
    </div>

    <button class="record" id="recordBtn">üé§ Record</button>
    <button class="stop" id="stopBtn">‚èπ Stop</button>

    <p id="status">Press Record and speak</p>
  </div>

  <script>
    const recordBtn = document.getElementById("recordBtn");
    const stopBtn = document.getElementById("stopBtn");
    const mouth = document.getElementById("mouth");
    const statusText = document.getElementById("status");

    let audioContext;
    let analyser;
    let microphone;
    let dataArray;
    let stream;

    recordBtn.onclick = async () => {
      try {
        stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      } catch (err) {
        statusText.textContent = "Microphone access denied";
        return;
      }

      audioContext = new AudioContext();
      analyser = audioContext.createAnalyser();
      microphone = audioContext.createMediaStreamSource(stream);
      microphone.connect(analyser);
      analyser.fftSize = 256;
      dataArray = new Uint8Array(analyser.frequencyBinCount);

      statusText.textContent = "üéô Listening... speak now";

      animateMouth();
    };

    stopBtn.onclick = () => {
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
      }
      mouth.style.height = "10px";
      statusText.textContent = "Stopped";
    };

    function animateMouth() {
      if (!analyser) return; // stop if analyser is gone

      analyser.getByteFrequencyData(dataArray);
      let volume = dataArray.reduce((a, b) => a + b) / dataArray.length;
      let mouthHeight = Math.min(60, volume);
      mouth.style.height = mouthHeight + "px";

      requestAnimationFrame(animateMouth);
    }
  </script>

</body>
</html>

